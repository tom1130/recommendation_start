{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Matrix Factorization 기반 추천\n",
    "  - 알고리즘 \n",
    "    - 메모리 기반 - collaborative filtering\n",
    "    - 모델 기반 - matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Matrix Factorization 방식의 원리\n",
    " - 행렬 요인화 - 사용자x아이템으로 구성된 하나의 행렬을 2개의 행렬로 분해하는 방법\n",
    " - R : rating matrix, P : User latent matrix, Q : item latent matrix\n",
    " - R을 사용자 행렬 P와 아이템 행렬 Q로 쪼개어 분석하는 것\n",
    " - $R \\approx P \\times Q^T = \\hat{R}$을 구하는 것\n",
    "  - 이 때 $\\hat{R}$은 $R$의 예측치이며 $R$과 비슷하게 되도록하는 $P$와 $Q$를 구하는 것이 목표\n",
    "  - $P$와 $Q$에는 $K$개의 요인의 값으로 행렬이 이루어져 있는데 $P$에서는 $K$개의 사용자의 특성을, $Q$에서는 $K$개의 아이템의 특성을 나타냄, 그리고 이를 잠재요인(latent factor)라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SGD(Stochastic Gradient Decent)를 사용한 MF 알고리즘\n",
    " - 알고리즘\n",
    "  1. 잠재요인 $K$의 개수 선정\n",
    "  2. 주어진 $K$에 따라 행렬 $P$,$Q$ 초기화\n",
    "  3. 예측 평점을 구함\n",
    "  4. $R$에 있는 실제 평점과 $\\hat{R}$의 예측 평점의 오차를 줄이기 위해 $P$,$Q$ 값 수정 -> SGE 방법 사용\n",
    "  5. 전체오차를 줄이기 위해 iteration 값 혹은 목표치에 근접할 때까지 3,4번을 반복\n",
    " - 수식 생략\n",
    " - 고려사항\n",
    "  1. 과적합 방지를 위해 정규화(regularization)항 추가\n",
    "  2. 사용자와 아이템의 경향성 -> 평가가 높거나 낮거나 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 SGD를 사용한 MF 기본 알고리즘\n",
    " - class 활용한 코딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utility import *\n",
    "from sklearn.utils import shuffle\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,_ , ratings = getData()\n",
    "ratings.reset_index(inplace=True)\n",
    "ratings = ratings.drop('timestamp',axis=1)\n",
    "ratings = ratings[['user_id','movie_id','rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MF class\n",
    "class MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings.fillna(0))\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero() # 0이 아닌 인덱스 리턴\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x,y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x,y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    def train(self):\n",
    "        # P행렬과 Q행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # (num_users, K)\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) # (num_items, K)\n",
    "        self.b_u = np.zeros(self.num_users) # (num_users,)\n",
    "        self.b_d = np.zeros(self.num_items) # (num_items,)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows,columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1,rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1)%10 ==0:\n",
    "                    print(f'iteration : {i+1} ; Train RMSE = {rmse}')\n",
    "        return training_process\n",
    "    \n",
    "    # 예측값 계산\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    # stochastic gradient descent \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i,j)\n",
    "            e = r-prediction\n",
    "            \n",
    "            self.b_u[i] += self.alpha*(e - self.beta*self.b_u[i])\n",
    "            self.b_d[j] += self.alpha*(e - self.beta*self.b_d[j])\n",
    "            \n",
    "            self.P[i,:] += self.alpha*(e*self.Q[j,:] - self.beta*self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha*(e*self.P[i,:] - self.beta*self.Q[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 10 ; Train RMSE = 0.9584980212318277\n",
      "iteration : 20 ; Train RMSE = 0.9373561041328844\n",
      "iteration : 30 ; Train RMSE = 0.9280656868205587\n",
      "iteration : 40 ; Train RMSE = 0.9225230970275939\n",
      "iteration : 50 ; Train RMSE = 0.9183510357036374\n",
      "iteration : 60 ; Train RMSE = 0.9143836352410551\n",
      "iteration : 70 ; Train RMSE = 0.9096480759600305\n",
      "iteration : 80 ; Train RMSE = 0.903154973886412\n",
      "iteration : 90 ; Train RMSE = 0.8941048495610546\n",
      "iteration : 100 ; Train RMSE = 0.8825226802288026\n"
     ]
    }
   ],
   "source": [
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values = 'rating')\n",
    "mf = MF(R_temp, 30, 0.001, 0.02, 100, True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 train/test 분리 MF 알고리즘\n",
    " - shuffle을 사용한 train_test split 방법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state = 1)\n",
    "cutoff = int(TRAIN_SIZE*len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEW_MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = np.array(ratings.fillna(0))\n",
    "        self.K = K\n",
    "        self.num_users, self.num_items = self.R.shape\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        # user_id, item_id를 R의 index와 매핑하기 위한 dictinary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.index):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_item_id = dict(index_user_id)\n",
    "    \n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero() # 0이 아닌 인덱스 리턴\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x,y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x,y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    def train(self):\n",
    "        # P행렬과 Q행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # (num_users, K)\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) # (num_items, K)\n",
    "        self.b_u = np.zeros(self.num_users) # (num_users,)\n",
    "        self.b_d = np.zeros(self.num_items) # (num_items,)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows,columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1,rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1)%10 ==0:\n",
    "                    print(f'iteration : {i+1} ; Train RMSE = {rmse}')\n",
    "        return training_process\n",
    "    \n",
    "    # 예측값 계산\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    # stochastic gradient descent \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i,j)\n",
    "            e = r-prediction\n",
    "            \n",
    "            self.b_u[i] += self.alpha*(e - self.beta*self.b_u[i])\n",
    "            self.b_d[j] += self.alpha*(e - self.beta*self.b_d[j])\n",
    "            \n",
    "            self.P[i,:] += self.alpha*(e*self.Q[j,:] - self.beta*self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha*(e*self.P[i,:] - self.beta*self.Q[j,:])\n",
    "            \n",
    "    # test set 선정\n",
    "    def set_test(self, ratings_test):\n",
    "        test_set = []\n",
    "        for i in range(len(ratings_test)):\n",
    "            x = self.user_id_index[ratings_test.iloc[i,0]]\n",
    "            y = self.item_id_index[ratings_test.iloc[i,1]]\n",
    "            z = ratings_test.iloc[i,2]\n",
    "            test_set.append([x,y,z])\n",
    "            self.R[x,y] = 0\n",
    "        self.test_set = test_set\n",
    "        return test_set\n",
    "    \n",
    "    def test_rmse(self):\n",
    "        error = 0\n",
    "        for one_set in self.test_set:\n",
    "            predicted = self.get_prediction(one_set[0],one_set[1])\n",
    "            error += pow(one_set[2] - predicted, 2)\n",
    "        return np.sqrt(error/len(self.test_set))\n",
    "    \n",
    "    def test(self):\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # (num_users, K)\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) # (num_items, K)\n",
    "        self.b_u = np.zeros(self.num_users) # (num_users,)\n",
    "        self.b_d = np.zeros(self.num_items) # (num_items,)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균\n",
    "        \n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows,columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            rmse_test = self.test_rmse()\n",
    "            training_process.append((i+1,rmse,rmse_test))\n",
    "            if self.verbose:\n",
    "                if (i+1)%10 ==0:\n",
    "                    print(f'iteration : {i+1} ; Train RMSE = {rmse} ; Test RMSE = {rmse_test:.4f}')\n",
    "        return training_process\n",
    "    \n",
    "    def get_one_prediction(self, user_id, item_id):\n",
    "        return self.get_prediction(self.user_id_index[user_id], self.item_id_index[item_id])\n",
    "    \n",
    "    def full_prediction(self):\n",
    "        return self.b + self.b_u[:,np.newaxis] + self.b_d[np.newaxis,:] + self.P.dot(self.Q.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 10 ; Train RMSE = 0.9659127342419507 ; Test RMSE = 0.9834\n",
      "iteration : 20 ; Train RMSE = 0.9409755423537928 ; Test RMSE = 0.9645\n",
      "iteration : 30 ; Train RMSE = 0.9297902938799715 ; Test RMSE = 0.9567\n",
      "iteration : 40 ; Train RMSE = 0.9230921523384817 ; Test RMSE = 0.9524\n",
      "iteration : 50 ; Train RMSE = 0.9183722245164371 ; Test RMSE = 0.9497\n",
      "iteration : 60 ; Train RMSE = 0.9145280396083484 ; Test RMSE = 0.9479\n",
      "iteration : 70 ; Train RMSE = 0.9109106173801017 ; Test RMSE = 0.9464\n",
      "iteration : 80 ; Train RMSE = 0.9069940853822434 ; Test RMSE = 0.9452\n",
      "iteration : 90 ; Train RMSE = 0.9022604065251304 ; Test RMSE = 0.9438\n",
      "iteration : 100 ; Train RMSE = 0.8961293023097657 ; Test RMSE = 0.9421\n"
     ]
    }
   ],
   "source": [
    "mf = NEW_MF(R_temp, 30, 0.001, 0.02, 100, True)\n",
    "test_set = mf.set_test(ratings_test)\n",
    "result = mf.test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 MF의 최적 파라미터 찾기\n",
    " - K가 커지면 over-fitting 발생\n",
    " - 최적의 iterations 및 K 찾기\n",
    "   1. 넓은 범위(50~260)에 대해 10간격으로 정확도 계산\n",
    "   2. 적절한 K에 대해 앞뒤 10정도의 범위에서 1의 간격으로 최적의 K값 확인\n",
    "   3. iteration은 충분히 큰 숫자를 통해 RMSE 변화를 관찰, 그 후 iteration 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50\n",
      "iteration : 10 ; Train RMSE = 0.9661141952422679 ; Test RMSE = 0.9834\n",
      "iteration : 20 ; Train RMSE = 0.9414200596935819 ; Test RMSE = 0.9644\n",
      "iteration : 30 ; Train RMSE = 0.9304779508966711 ; Test RMSE = 0.9566\n",
      "iteration : 40 ; Train RMSE = 0.9240709602016239 ; Test RMSE = 0.9523\n",
      "iteration : 50 ; Train RMSE = 0.9197038880057534 ; Test RMSE = 0.9497\n",
      "iteration : 60 ; Train RMSE = 0.916321739855097 ; Test RMSE = 0.9478\n",
      "iteration : 70 ; Train RMSE = 0.9133089060051923 ; Test RMSE = 0.9465\n",
      "iteration : 80 ; Train RMSE = 0.9102149333664625 ; Test RMSE = 0.9453\n",
      "iteration : 90 ; Train RMSE = 0.9065776791366428 ; Test RMSE = 0.9441\n",
      "iteration : 100 ; Train RMSE = 0.9018738128879455 ; Test RMSE = 0.9426\n",
      "iteration : 110 ; Train RMSE = 0.895501816508779 ; Test RMSE = 0.9405\n",
      "iteration : 120 ; Train RMSE = 0.8868886554709896 ; Test RMSE = 0.9378\n",
      "iteration : 130 ; Train RMSE = 0.875760644911509 ; Test RMSE = 0.9344\n",
      "iteration : 140 ; Train RMSE = 0.8623222944187282 ; Test RMSE = 0.9307\n",
      "iteration : 150 ; Train RMSE = 0.8470513707003304 ; Test RMSE = 0.9272\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-30-6661dbe8d391>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mmf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNEW_MF\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mR_temp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mK\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.001\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0.02\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtest_set\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_test\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mindex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mK\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-2346816f8df2>\u001b[0m in \u001b[0;36mtest\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    107\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miterations\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m             \u001b[0mrmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mrmse_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtest_rmse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-2346816f8df2>\u001b[0m in \u001b[0;36msgd\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     66\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msgd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     67\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 68\u001b[1;33m             \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     69\u001b[0m             \u001b[0me\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mr\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-28-2346816f8df2>\u001b[0m in \u001b[0;36mget_prediction\u001b[1;34m(self, i, j)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;31m# 예측값 계산\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_prediction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m         \u001b[0mprediction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_u\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mb_d\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mP\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mQ\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mprediction\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# 최적의 K 구하기\n",
    "results = []\n",
    "index = []\n",
    "for K in range(50,261,10):\n",
    "    print(f'K = {K}')\n",
    "    mf = NEW_MF(R_temp, K, 0.001, 0.02, 300, True)\n",
    "    test_set = mf.set_test(ratings_test)\n",
    "    result = mf.test()\n",
    "    index.append(K)\n",
    "    results.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 최적의 iterations 구하기\n",
    "summary = []\n",
    "for i in range(len(results)):\n",
    "    RMSE = []\n",
    "    for result in results[i]:\n",
    "        RMSE.append(result[2])\n",
    "    min = np.min(RMSE)\n",
    "    j = RMSE.index(min)\n",
    "    summary.append([index[i],j+1, RMSE[j]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 그래프 그리기\n",
    "plt.plot(index,[x[2] for x in summary])\n",
    "plt.ylim(0.89, 0.94)\n",
    "plt.xlabel('K')\n",
    "plt.ylabel('RMSE')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7 MF와 SVD\n",
    " - SVD(singular value decomposition) - 3개의 행렬로 분해, 이를 원래의 행렬로 재현시키는 방법\n",
    "   - (mxn) = (mxm)x(mxn)x(nxn)\n",
    "   - null 값에 대한 계산이 되지 않음\n",
    "     - 이를 0으로 치환했을 때 0으로 재현하려고 하기 때문에 추천시스템에 적합하지 않음\n",
    "     - 반면 MF의 경우, null 값에 대해 값을 주기 때문에 추천시스템에 사용 가능"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
