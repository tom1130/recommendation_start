{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Matrix Factorization 기반 추천\n",
    "  - 알고리즘 \n",
    "    - 메모리 기반 - collaborative filtering\n",
    "    - 모델 기반 - matrix factorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1 Matrix Factorization 방식의 원리\n",
    " - 행렬 요인화 - 사용자x아이템으로 구성된 하나의 행렬을 2개의 행렬로 분해하는 방법\n",
    " - R : rating matrix, P : User latent matrix, Q : item latent matrix\n",
    " - R을 사용자 행렬 P와 아이템 행렬 Q로 쪼개어 분석하는 것\n",
    " - $R \\approx P \\times Q^T = \\hat{R}$을 구하는 것\n",
    "  - 이 때 $\\hat{R}$은 $R$의 예측치이며 $R$과 비슷하게 되도록하는 $P$와 $Q$를 구하는 것이 목표\n",
    "  - $P$와 $Q$에는 $K$개의 요인의 값으로 행렬이 이루어져 있는데 $P$에서는 $K$개의 사용자의 특성을, $Q$에서는 $K$개의 아이템의 특성을 나타냄, 그리고 이를 잠재요인(latent factor)라고 부름"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2 SGD(Stochastic Gradient Decent)를 사용한 MF 알고리즘\n",
    " - 알고리즘\n",
    "  1. 잠재요인 $K$의 개수 선정\n",
    "  2. 주어진 $K$에 따라 행렬 $P$,$Q$ 초기화\n",
    "  3. 예측 평점을 구함\n",
    "  4. $R$에 있는 실제 평점과 $\\hat{R}$의 예측 평점의 오차를 줄이기 위해 $P$,$Q$ 값 수정 -> SGE 방법 사용\n",
    "  5. 전체오차를 줄이기 위해 iteration 값 혹은 목표치에 근접할 때까지 3,4번을 반복\n",
    " - 수식 생략\n",
    " - 고려사항\n",
    "  1. 과적합 방지를 위해 정규화(regularization)항 추가\n",
    "  2. 사용자와 아이템의 경향성 -> 평가가 높거나 낮거나 할 수 있음"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3 SGD를 사용한 MF 기본 알고리즘\n",
    " - class 활용한 코딩 진행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utility import *\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ ,_ , ratings = getData()\n",
    "ratings.reset_index(inplace=True)\n",
    "ratings = ratings.drop('timestamp',axis=1)\n",
    "ratings = ratings[['user_id','movie_id','rating']].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MF class\n",
    "class MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose=True):\n",
    "        self.R = np.array(ratings.fillna(0))\n",
    "        self.num_users, self.num_items = np.shape(self.R)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "    \n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero() # 0이 아닌 인덱스 리턴\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x,y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x,y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    def train(self):\n",
    "        # P행렬과 Q행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # (num_users, K)\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) # (num_items, K)\n",
    "        self.b_u = np.zeros(self.num_users) # (num_users,)\n",
    "        self.b_d = np.zeros(self.num_items) # (num_items,)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows,columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1,rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1)%10 ==0:\n",
    "                    print(f'iteration : {i+1} ; Train RMSE = {rmse}')\n",
    "        return training_process\n",
    "    \n",
    "    # 예측값 계산\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    # stochastic gradient descent \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i,j)\n",
    "            e = r-prediction\n",
    "            \n",
    "            self.b_u[i] += self.alpha*(e - self.beta*self.b_u[i])\n",
    "            self.b_d[j] += self.alpha*(e - self.beta*self.b_d[j])\n",
    "            \n",
    "            self.P[i,:] += self.alpha*(e*self.Q[j,:] - self.beta*self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha*(e*self.P[i,:] - self.beta*self.Q[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iteration : 10 ; Train RMSE = 0.9584980212318277\n",
      "iteration : 20 ; Train RMSE = 0.9373561041328844\n",
      "iteration : 30 ; Train RMSE = 0.9280656868205587\n",
      "iteration : 40 ; Train RMSE = 0.9225230970275939\n",
      "iteration : 50 ; Train RMSE = 0.9183510357036374\n",
      "iteration : 60 ; Train RMSE = 0.9143836352410551\n",
      "iteration : 70 ; Train RMSE = 0.9096480759600305\n",
      "iteration : 80 ; Train RMSE = 0.903154973886412\n",
      "iteration : 90 ; Train RMSE = 0.8941048495610546\n",
      "iteration : 100 ; Train RMSE = 0.8825226802288026\n"
     ]
    }
   ],
   "source": [
    "R_temp = ratings.pivot(index='user_id', columns='movie_id', values = 'rating')\n",
    "mf = MF(R_temp, 30, 0.001, 0.02, 100, True)\n",
    "train_process = mf.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4 train/test 분리 MF 알고리즘\n",
    " - shuffle을 사용한 train_test split 방법 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAIN_SIZE = 0.75\n",
    "ratings = shuffle(ratings, random_state = 1)\n",
    "cutoff = int(TRAIN_SIZE*len(ratings))\n",
    "ratings_train = ratings.iloc[:cutoff]\n",
    "ratings_test = ratings.iloc[cutoff:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NEW_MF:\n",
    "    def __init__(self, ratings, K, alpha, beta, iterations, verbose = True):\n",
    "        self.R = np.array(ratings)\n",
    "        self.K = K\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.iterations = iterations\n",
    "        self.verbose = verbose\n",
    "        # user_id, item_id를 R의 index와 매핑하기 위한 dictinary 생성\n",
    "        item_id_index = []\n",
    "        index_item_id = []\n",
    "        for i, one_id in enumerate(ratings):\n",
    "            item_id_index.append([one_id, i])\n",
    "            index_item_id.append([i, one_id])\n",
    "        self.item_id_index = dict(item_id_index)\n",
    "        self.index_item_id = dict(index_item_id)\n",
    "        user_id_index = []\n",
    "        index_user_id = []\n",
    "        for i, one_id in enumerate(ratings.index):\n",
    "            user_id_index.append([one_id, i])\n",
    "            index_user_id.append([i, one_id])\n",
    "        self.user_id_index = dict(user_id_index)\n",
    "        self.index_item_id = dict(index_user_id)\n",
    "    \n",
    "    # RMSE 계산\n",
    "    def rmse(self):\n",
    "        xs, ys = self.R.nonzero() # 0이 아닌 인덱스 리턴\n",
    "        self.predictions = []\n",
    "        self.errors = []\n",
    "        for x,y in zip(xs, ys):\n",
    "            prediction = self.get_prediction(x,y)\n",
    "            self.predictions.append(prediction)\n",
    "            self.errors.append(self.R[x,y] - prediction)\n",
    "        self.predictions = np.array(self.predictions)\n",
    "        self.errors = np.array(self.errors)\n",
    "        return np.sqrt(np.mean(self.errors**2))\n",
    "    \n",
    "    def train(self):\n",
    "        # P행렬과 Q행렬 초기화\n",
    "        self.P = np.random.normal(scale=1./self.K, size=(self.num_users, self.K)) # (num_users, K)\n",
    "        self.Q = np.random.normal(scale=1./self.K, size=(self.num_items, self.K)) # (num_items, K)\n",
    "        self.b_u = np.zeros(self.num_users) # (num_users,)\n",
    "        self.b_d = np.zeros(self.num_items) # (num_items,)\n",
    "        self.b = np.mean(self.R[self.R.nonzero()]) # 전체 평균\n",
    "        rows, columns = self.R.nonzero()\n",
    "        self.samples = [(i,j,self.R[i,j]) for i,j in zip(rows,columns)]\n",
    "        \n",
    "        training_process = []\n",
    "        for i in range(self.iterations):\n",
    "            np.random.shuffle(self.samples)\n",
    "            self.sgd()\n",
    "            rmse = self.rmse()\n",
    "            training_process.append((i+1,rmse))\n",
    "            if self.verbose:\n",
    "                if (i+1)%10 ==0:\n",
    "                    print(f'iteration : {i+1} ; Train RMSE = {rmse}')\n",
    "        return training_process\n",
    "    \n",
    "    # 예측값 계산\n",
    "    def get_prediction(self, i, j):\n",
    "        prediction = self.b + self.b_u[i] + self.b_d[j] + self.P[i,:].dot(self.Q[j,:].T)\n",
    "        return prediction\n",
    "    \n",
    "    # stochastic gradient descent \n",
    "    def sgd(self):\n",
    "        for i, j, r in self.samples:\n",
    "            prediction = self.get_prediction(i,j)\n",
    "            e = r-prediction\n",
    "            \n",
    "            self.b_u[i] += self.alpha*(e - self.beta*self.b_u[i])\n",
    "            self.b_d[j] += self.alpha*(e - self.beta*self.b_d[j])\n",
    "            \n",
    "            self.P[i,:] += self.alpha*(e*self.Q[j,:] - self.beta*self.P[i,:])\n",
    "            self.Q[j,:] += self.alpha*(e*self.P[i,:] - self.beta*self.Q[j,:])\n",
    "            \n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
